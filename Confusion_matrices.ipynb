{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d7f64e3",
   "metadata": {},
   "source": [
    "# Problem set 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da385c6e",
   "metadata": {},
   "source": [
    "Peijin Li"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f1f64e",
   "metadata": {},
   "source": [
    "#### 1.Construct a feature matrix and target array to predict whether an individual defaults on their debt. Convert the categorical variables to binary numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2bc727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Management/Investigation\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "### Read in data\n",
    "default = pd.read_csv(\"default.csv\")\n",
    "##Construct a feature matrix \n",
    "X_98 = default.drop('default',axis=1)\n",
    "##target array to predict whether an individual defaults on their debt.\n",
    "y_98 = default['default']\n",
    "#print out the feature matrix \n",
    "X_98.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc2a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert the categorical variables to binary numeric values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Instantiate class\n",
    "le = LabelEncoder()\n",
    "le_stu = LabelEncoder()\n",
    "# Apply to purchased column\n",
    "default[\"default_dum\"] = le.fit_transform(default[\"default\"])\n",
    "default[\"student_dum\"] = le_stu.fit_transform(default[\"student\"])\n",
    "df=default.filter([\"default_dum\",\"student_dum\",\"balance\",\"income\"])\n",
    "df=df.rename(columns={\"default_dum\":\"default\",\"student_dum\":\"student\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f509cf",
   "metadata": {},
   "source": [
    "#### 2.Calculate the base rate for the positive class, default=1. In other words, what proportion of borrowers in the dataset are classified as having defaulted? What challenges might this present for your analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55e5c100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0333"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the base rate for the positive class, default=1.\n",
    "positive=df['default'].value_counts()[1]\n",
    "negative=df['default'].value_counts()[0]\n",
    "positive_class_base_rate=positive/(positive+negative)\n",
    "positive_class_base_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e79f733",
   "metadata": {},
   "source": [
    "This leads to the class imbalance problem. Machine learning algorithms assume data is equally distributed. So, when we have a class imbalance, the machine learning classifier tends to be more biased towards the majority class, causing bad classification of the minority class.It occurs because the conventional machine learning algorithm cost function constantly attempts to optimize quantities such as error rate without considering the data distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81064b1e",
   "metadata": {},
   "source": [
    "#### 3.Split the data into training and test sets, holding out 20% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b542de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split (just using Pandas)\n",
    "#Create a training and test set with 20% of the data held out for testing.\n",
    "train = df.sample(frac=.80).reset_index(drop=True)\n",
    "test = df.drop(train.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b392054",
   "metadata": {},
   "source": [
    "#### 4.Fit each of the following models using the training data, and compute the accuracy rate using the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c7daa4",
   "metadata": {},
   "source": [
    "(a) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc2f964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Logistic Regression models using the training data\n",
    "# Set feature (now use all feautures) and target\n",
    "X = df.drop(\"default\", axis=1)\n",
    "y = df[[\"default\"]]\n",
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=98)\n",
    "# Import class from Logistic_model module within sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Instantiate model object\n",
    "lr = LogisticRegression()\n",
    "# Fit model to training data\n",
    "lr.fit(X_train, y_train)\n",
    "# Make predictions on unseen data using the test set\n",
    "y_test_pred = lr.predict(X_test)\n",
    "##remove the extra braces\n",
    "import numpy as np\n",
    "y_test_pred=np.ravel(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c00fe1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Logistic Regression model: 0.9665\n"
     ]
    }
   ],
   "source": [
    "#compute the accuracy rate using the test data\n",
    "# Import metrics from sklearn\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy score of Logistic Regression model:\", metrics.accuracy_score(y_test,y_pred=y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5dfb6f",
   "metadata": {},
   "source": [
    "(b) Support Vector Machine (set C = 1 and probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34412b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import class from LinearSVC_model module within sklearn\n",
    "from sklearn.svm import SVC\n",
    "# Instantiate model object\n",
    "svm=SVC(C=1, probability = True)\n",
    "# Fit model to training data\n",
    "svm.fit(X_train, y_train)\n",
    "# Make predictions on unseen data using the test set\n",
    "y_test_pred_1=svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ed29d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Support Vector Machine model: 0.9675\n"
     ]
    }
   ],
   "source": [
    "##compute the accuracy rate using the test data\n",
    "print(\"Accuracy score of Support Vector Machine model:\", metrics.accuracy_score(y_test,y_pred=y_test_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94214423",
   "metadata": {},
   "source": [
    "#### 5.For each of the models in #4, generate predictions and compute the recall score. Discuss the performance of the models with respect to accuracy and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb048c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate predictions with Logistic Regression model \n",
    "y_test_pred = lr.predict(X_test)\n",
    "#generate predictions with Support Vector Machine model \n",
    "y_test_pred_1=svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1d99a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score of Logistic Regression model: 0.18461538461538463\n",
      "Recall score of Support Vector Machine model: 0.0\n"
     ]
    }
   ],
   "source": [
    "##compute the recall score of Logistic Regression\n",
    "print(\"Recall score of Logistic Regression model:\", metrics.recall_score(y_test,y_pred=y_test_pred))\n",
    "##compute the recall score of Support Vector Machine\n",
    "print(\"Recall score of Support Vector Machine model:\", metrics.recall_score(y_test,y_pred=y_test_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a83e0ef",
   "metadata": {},
   "source": [
    "Discuss the performance of the models:Accuracy=(TP+TN)/(TP+FP+TN+FN). The accuracy score of Logistic Regression model is 0.9665, and the accuracy score of Support Vector Machine model is 0.9675,slightly higher than the Logistic Regression model. This means compared with Logistic Regression model, Support Vector Machine model's prediction is more accurate. REC(recall score) =TP/(FN+TP). The larger of REC, the greater(so, in this case,Support Vector Machine model performs worse), which means it does worse on minimizing the chances of missing positive cases. Actually, Support Vector Machine model predicates no case to be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3268e421",
   "metadata": {},
   "source": [
    "#### 6.Compute and show a confusion matrix. Is either recall or precision more important than the other in this domain? Why or why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baa54083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_7da04_row0_col0,#T_7da04_row0_col1{\n",
       "            background-color:  #ffff66;\n",
       "            color:  #000000;\n",
       "        }#T_7da04_row1_col0,#T_7da04_row1_col1{\n",
       "            background-color:  #008066;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_7da04_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Predicted negative</th>        <th class=\"col_heading level0 col1\" >Predicted positive</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_7da04_level0_row0\" class=\"row_heading level0 row0\" >Actual negative</th>\n",
       "                        <td id=\"T_7da04_row0_col0\" class=\"data row0 col0\" >1921</td>\n",
       "                        <td id=\"T_7da04_row0_col1\" class=\"data row0 col1\" >14</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7da04_level0_row1\" class=\"row_heading level0 row1\" >Actual positive</th>\n",
       "                        <td id=\"T_7da04_row1_col0\" class=\"data row1 col0\" >53</td>\n",
       "                        <td id=\"T_7da04_row1_col1\" class=\"data row1 col1\" >12</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x267025de040>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix of Logistic Regression model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_test_pred)\n",
    "# Assess using relevant metrics: confusion matrix   true/pred   #  no/no |  no/yes # yes/no |  yes/yes\n",
    "pd.DataFrame(confusion_matrix(y_test, y_test_pred),\n",
    "            columns=[\"Predicted negative\", \"Predicted positive\"],\n",
    "            index=[\"Actual negative\",\"Actual positive\"]).style.background_gradient(cmap=\"summer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7d077f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_6ad4d_row0_col0{\n",
       "            background-color:  #ffff66;\n",
       "            color:  #000000;\n",
       "        }#T_6ad4d_row0_col1,#T_6ad4d_row1_col0,#T_6ad4d_row1_col1{\n",
       "            background-color:  #008066;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_6ad4d_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Predicted negative</th>        <th class=\"col_heading level0 col1\" >Predicted positive</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_6ad4d_level0_row0\" class=\"row_heading level0 row0\" >Actual negative</th>\n",
       "                        <td id=\"T_6ad4d_row0_col0\" class=\"data row0 col0\" >1935</td>\n",
       "                        <td id=\"T_6ad4d_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6ad4d_level0_row1\" class=\"row_heading level0 row1\" >Actual positive</th>\n",
       "                        <td id=\"T_6ad4d_row1_col0\" class=\"data row1 col0\" >65</td>\n",
       "                        <td id=\"T_6ad4d_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2670628b0d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix of Support Vector Machine model\n",
    "confusion_matrix(y_test, y_test_pred_1)\n",
    "# Assess using relevant metrics: confusion matrix   true/pred   #  no/no |  no/yes # yes/no |  yes/yes\n",
    "pd.DataFrame(confusion_matrix(y_test, y_test_pred_1),\n",
    "            columns=[\"Predicted negative\", \"Predicted positive\"],\n",
    "            index=[\"Actual negative\",\"Actual positive\"]).style.background_gradient(cmap=\"summer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b79200",
   "metadata": {},
   "source": [
    "In this domain, recall is more important. Because it actually is more costly than predicting something is not default and it turned out to be. REC(recall score) =TP/(FN+TP) can be used to minimize the chances of missing positive cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1647c90",
   "metadata": {},
   "source": [
    "#### 7.For this part of the assignment, you will use data that oversamples the positive class (subset data so default=1 )."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6579aa4",
   "metadata": {},
   "source": [
    "(a) Create a new dataframe that retains all negative class observations and oversamples the positive class with replacement so that the base rate for the positive class is 50%. This dataframe should have 19,334 observations (n+ = 9, 667, n− =9, 667)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8a4ee46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9667, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new dataframe that retains all negative class observations \n",
    "df_negative=df.loc[df.default == 0]\n",
    "df_negative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcc6aa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampled:\n",
      "default\n",
      "0          9667\n",
      "1          9667\n",
      "dtype: int64\\mZ\n"
     ]
    }
   ],
   "source": [
    "#oversamples the positive class with replacement so that the base rate for the positive class is 50%.\n",
    "# Import class\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# Instantiate\n",
    "over = RandomOverSampler(random_state=98)\n",
    "# split the data\n",
    "X_1 = df.drop(\"default\", axis=1)\n",
    "y_1 = df[[\"default\"]]\n",
    "# Fit features and target\n",
    "x_over, y_over = over.fit_resample(X_1, y_1)\n",
    "# Check target classes\n",
    "print(f\"Oversampled:\\n{y_over.value_counts()}\\mZ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aeb2ce",
   "metadata": {},
   "source": [
    "(b) Repeat #3, #4 and #5 with this new data—fit each of the models on the training data and compute their accuracy and recall scores on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab86c99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine x_over and y_over\n",
    "df_oversample=pd.concat([x_over,y_over],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c52b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "##(3)\n",
    "# Train-Test split (just using Pandas)\n",
    "#Create a training and test set with 20% of the data held out for testing.\n",
    "train_1 = df_oversample.sample(frac=.80).reset_index(drop=True)\n",
    "test_1 = df_oversample.drop(train_1.index).reset_index(drop=True)\n",
    "##(4.a)\n",
    "# Fit Logistic Regression models using the training data\n",
    "# Set feature (now use all feautures) and target\n",
    "X_os = df_oversample.drop(\"default\", axis=1)\n",
    "y_os = df_oversample[[\"default\"]]\n",
    "# Split data\n",
    "X_train_os, X_test_os, y_train_os, y_test_os = train_test_split(X_os, y_os, test_size=0.2, random_state=98)\n",
    "# Instantiate model object\n",
    "lr_os = LogisticRegression()\n",
    "# Fit model to training data\n",
    "lr_os.fit(X_train_os, y_train_os)\n",
    "# Make predictions on unseen data using the test set\n",
    "y_test_pred_os = lr_os.predict(X_test_os)\n",
    "##remove the extra braces\n",
    "y_test_pred_os=np.ravel(y_test_pred_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "657184cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##(4.b)\n",
    "# Instantiate model object\n",
    "svm_os=SVC(C=1, probability = True)\n",
    "# Fit model to training data\n",
    "svm_os.fit(X_train_os, y_train_os)\n",
    "# Make predictions on unseen data using the test set\n",
    "y_test_pred_1_os=svm_os.predict(X_test_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dddb1c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Logistic Regression model: 0.8709594000517197\n",
      "Recall score of Logistic Regression model: 0.8934725848563969\n"
     ]
    }
   ],
   "source": [
    "##(5)\n",
    "#compute the accuracy rate using the test data\n",
    "print(\"Accuracy score of Logistic Regression model:\", metrics.accuracy_score(y_test_os,y_pred=y_test_pred_os))\n",
    "##compute the recall score of Logistic Regression\n",
    "print(\"Recall score of Logistic Regression model:\", metrics.recall_score(y_test_os,y_pred=y_test_pred_os))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9493b0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Support Vector Machine model: 0.8675976208947505\n",
      "Recall score of Support Vector Machine model: 0.9044386422976501\n"
     ]
    }
   ],
   "source": [
    "##compute the accuracy rate using the test data\n",
    "print(\"Accuracy score of Support Vector Machine model:\", metrics.accuracy_score(y_test_os,y_pred=y_test_pred_1_os))\n",
    "##compute the recall score of Support Vector Machine\n",
    "print(\"Recall score of Support Vector Machine model:\", metrics.recall_score(y_test_os,y_pred=y_test_pred_1_os))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0e95e7",
   "metadata": {},
   "source": [
    "(c) Discuss the performance tradeoff associated with oversampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a162ba",
   "metadata": {},
   "source": [
    "For both models, with oversampling, the accuracy score of the prediction decreses, and the recall score increases. The random oversampling may increase the likelihood of overfitting occurring, since it makes exact copies of the minority class examples. In this way, a symbolic classifier, for instance, might construct rules that are apparently accurate, but actually cove one replicated example. So, when we apply thie model to fit the testing data, the accuracy decreases. With more minority class available, the model performs better on identify positive cases, which explains the increases of recall score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff242b61",
   "metadata": {},
   "source": [
    "#### 8.For this part of the assignment, you will use data that undersamples the negative class (subset data so default=0 )."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8960c0",
   "metadata": {},
   "source": [
    "(a) Create a new dataframe that retains all positive class observations and undersamples the negative class so that the base rate for the positive class is 50%. This dataframe should have 666 observations (n+ = 333, n− = 333)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a69eec73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Create a new dataframe that retains all positive class observations\n",
    "df_positive=df.loc[df.default == 1]\n",
    "df_positive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91f5698b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampled:\n",
      "default\n",
      "0          333\n",
      "1          333\n",
      "dtype: int64\\mZ\n"
     ]
    }
   ],
   "source": [
    "#undersamples the negative class with replacement so that the base rate for the positive class is 50%.\n",
    "# Import class\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Instantiate\n",
    "under = RandomUnderSampler(random_state=98)\n",
    "# split the data\n",
    "X_2 = df.drop(\"default\", axis=1)\n",
    "y_2 = df[[\"default\"]]\n",
    "# Fit features and target\n",
    "x_under, y_under = under.fit_resample(X_2, y_2)\n",
    "# Check target classes\n",
    "print(f\"Undersampled:\\n{y_under.value_counts()}\\mZ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f56c9c",
   "metadata": {},
   "source": [
    "(b) Repeat #3, #4 and #5 with this new data—fit each of the models on the training data and compute their accuracy and recall scores on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24df3391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine x_under and y_under\n",
    "df_undersample=pd.concat([x_under,y_under],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c82af741",
   "metadata": {},
   "outputs": [],
   "source": [
    "##(3)\n",
    "# Train-Test split (just using Pandas)\n",
    "#Create a training and test set with 20% of the data held out for testing.\n",
    "train_2 = df_undersample.sample(frac=.80).reset_index(drop=True)\n",
    "test_2 = df_undersample.drop(train_2.index).reset_index(drop=True)\n",
    "##(4.a)\n",
    "# Fit Logistic Regression models using the training data\n",
    "# Set feature (now use all feautures) and target\n",
    "X_ud = df_undersample.drop(\"default\", axis=1)\n",
    "y_ud = df_undersample[[\"default\"]]\n",
    "# Split data\n",
    "X_train_ud, X_test_ud, y_train_ud, y_test_ud = train_test_split(X_ud, y_ud, test_size=0.2, random_state=98)\n",
    "# Instantiate model object\n",
    "lr_ud = LogisticRegression()\n",
    "# Fit model to training data\n",
    "lr_ud.fit(X_train_ud, y_train_ud)\n",
    "# Make predictions on unseen data using the test set\n",
    "y_test_pred_ud = lr_os.predict(X_test_ud)\n",
    "##remove the extra braces\n",
    "y_test_pred_ud=np.ravel(y_test_pred_ud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2065e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##(4.b)\n",
    "# Instantiate model object\n",
    "svm_ud=SVC(C=1, probability = True)\n",
    "# Fit model to training data\n",
    "svm_ud.fit(X_train_ud, y_train_ud)\n",
    "# Make predictions on unseen data using the test set\n",
    "y_test_pred_1_ud=svm_os.predict(X_test_ud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11926b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Logistic Regression model: 0.8432835820895522\n",
      "Recall score of Logistic Regression model: 0.8382352941176471\n"
     ]
    }
   ],
   "source": [
    "##(5)\n",
    "#compute the accuracy rate using the test data\n",
    "print(\"Accuracy score of Logistic Regression model:\", metrics.accuracy_score(y_test_ud,y_pred=y_test_pred_ud))\n",
    "##compute the recall score of Logistic Regression\n",
    "print(\"Recall score of Logistic Regression model:\", metrics.recall_score(y_test_ud,y_pred=y_test_pred_ud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15218a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Support Vector Machine model: 0.8283582089552238\n",
      "Recall score of Support Vector Machine model: 0.8529411764705882\n"
     ]
    }
   ],
   "source": [
    "##compute the accuracy rate using the test data\n",
    "print(\"Accuracy score of Support Vector Machine model:\", metrics.accuracy_score(y_test_ud,y_pred=y_test_pred_1_ud))\n",
    "##compute the recall score of Support Vector Machine\n",
    "print(\"Recall score of Support Vector Machine model:\", metrics.recall_score(y_test_ud,y_pred=y_test_pred_1_ud))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb595de2",
   "metadata": {},
   "source": [
    "(c) Discuss the performance tradeoff associated with undersampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85535f5",
   "metadata": {},
   "source": [
    "For both models, with undersampling, the accuracy score of the prediction decreses, and the recall score increases. In random undersampling, vast quantities of data are discarded.This can be highly problematic, as the loss of such data can make the decision boundary between the minority and majority instances harder to learn, resulting in a loss in classification performance. So, when we apply the model to fit the testing data, the accuracy decreases. With a more balanced dataset, the model performs better on identify positive cases, which explains the increases of recall score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d34f66",
   "metadata": {},
   "source": [
    "#### 9.You have now examined the following scenarios:\n",
    "Original data (n+ = 333, n− = 9, 667)\n",
    "Oversampling the positive class (n+ = 9, 667, n− = 9, 667)\n",
    "Undersampling the negative class (n+ = 333, n− = 333)\n",
    "Based on your analysis, which strategy would you employ to address the imbalanced class problem? Which model would you select as the “best” model? Explain your rationale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53295c38",
   "metadata": {},
   "source": [
    "In this case, I woule like to select oversampling the positive class model as the “best” model. First of all, I would like to discard the model of the original data, because with the inbalanced class problem, the model performs poor with a recall score of 0(Support Vector Machine model) and 0.184(Logistic Regression model), which means in this domain, there is a high chance that the model miss positive cases in its prediction. I think oversampling is better than undersampling, because the accuracy score of oversampling is higher than undersampling. This means oversampling performs better than undersampling on predicting unseen data. This is because undersampling discards vast quantities of data, render the decision boundary between the minority and majority instances harder to learn, resulting in a loss in classification performance. And with more data to learn, oversampling model also performs better than undersampling model referring to recall scores, which means oversampling model performs better on identify positive cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
